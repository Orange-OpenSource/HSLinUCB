{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software Name : HSLinUCB\n",
    "# SPDX-FileCopyrightText: Copyright (c) 2021 Orange\n",
    "# SPDX-License-Identifier: GPL-2.0\n",
    "#\n",
    "# This software is distributed under the GNU General Public License v2.0 license\n",
    "#\n",
    "# Author: David DELANDE <david.delande@orange.com> et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from math import *\n",
    "import scipy.stats as stats\n",
    "from numpy.linalg import inv\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import random\n",
    "import numpy.linalg\n",
    "import copy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm import trange\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.random.seed(1)\n",
    "\n",
    "import pickle\n",
    "from collections import deque , OrderedDict\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "import h5py\n",
    "from lib.CogscalingLib import Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionFile=\"my_new_dataset.h5\" #Set the dataset to use. If the dataset does not exist and self.record == True in environment (see below) the new dataset will be created\n",
    "environment_orchestrator = Orchestrator(debug=False, sessionFile=sessionFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Activate debug on orchestrator thread\")\n",
    "status, message = environment_orchestrator.activateDebug(component='orchestrator')\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"Set front-dynamic-component deployment limit to min=1 and max=15\")\n",
    "status, message = environment_orchestrator.setDeploymentLimit(deployment=\"front-dynamic-component\", min=1, max=15)\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"set zipkin thread to collect latency from istio ingress and from front-dynamic-component on namespace default\")\n",
    "status, message = environment_orchestrator.setZipkinService(services=['istio-ingressgateway','front-dynamic-component.default'])\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"set prometheus thread to collect system metric for front-dynamic-component deployment\")\n",
    "status, message = environment_orchestrator.setPrometheusService(deployments=['front-dynamic-component'])\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"set prometheus thread history buffer size to keep 1 system metrics history\")\n",
    "status, message = environment_orchestrator.changePrometheusTraceNumber(trace_number=1)\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"Set the number of measures taken from prometheus before raising the event scaling done\")\n",
    "status, message = environment_orchestrator.setSampleNumberBeforeAcceptScaling(sampleNumber=1)\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"set zipkin thread history buffer size to keep 4000 latency metrics history\")\n",
    "status, message = environment_orchestrator.changeZipkinTraceNumber(trace_number=4000)\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"set zipkin thread lookback time window to 10 seconds\")\n",
    "status, message = environment_orchestrator.setZipkinLookback(lookback=12)\n",
    "print(\"message:\", message)\n",
    "\n",
    "print(\"Display orchestrator configuration\")\n",
    "status, message = environment_orchestrator.getConfig()\n",
    "print(\"configuration:\", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvTest(): \n",
    "    def __init__(self, narms, level=1,max_level = 25, latency_ref = 600, debug = False):\n",
    "        self.latency_ref = latency_ref\n",
    "        self.min_level = 1\n",
    "        self.max_level = max_level\n",
    "        self.level = level\n",
    "        self.debug = debug\n",
    "        self.narms = narms\n",
    "        self.loads = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]\n",
    "        self.levels = [1,2,3,4,5,6,7,8,9,10]\n",
    "        self.sessionFile=sessionFile\n",
    "        self.oracle_cheat = np.full((np.max(self.loads) +1, len(self.levels) + 1),2)\n",
    "        self.previous_states = []\n",
    "        self.current_states = []\n",
    "        self.previous_duration = 0\n",
    "        self.current_duration = 0\n",
    "        self.previous_rq = 0\n",
    "        self.current_rq = 0\n",
    "        self.targetPattern = []\n",
    "        self.rounds = 0\n",
    "        self.replay = False # Set to True to read context from the dataset. replay and record are mutually exclusive.\n",
    "        self.record = False # Set to True to record context in the dataset. replay and record are mutually exclusive.\n",
    "        super().__init__()\n",
    "        return\n",
    "    \n",
    "    def reset(self, narms, target, level,max_level, latency_ref):\n",
    "        self.level = level\n",
    "        self.rounds = 0\n",
    "        self.step = 0\n",
    "                    \n",
    "    def moving_mean(self,measure,order):\n",
    "        result = []\n",
    "        if order%2 == 0:\n",
    "            m = order / 2\n",
    "            m = int(m)\n",
    "            for index in range(0, len(measure)):\n",
    "                if index < m or index + m + 1 > len(measure):\n",
    "                    continue\n",
    "                sum1 = 0\n",
    "                sum2 = 0\n",
    "                for index_value in range(index -m, index + m):\n",
    "                    sum1 = sum1 + measure[index_value]\n",
    "                    sum2 = sum2 + measure[index_value + 1]\n",
    "                mean1 = (1/(2*m)) * sum1\n",
    "                mean2 = (1/(2*m)) * sum2\n",
    "                result.append((mean1 + mean2) / 2)\n",
    "        else:\n",
    "            m = (order - 1) / 2\n",
    "            m = int(m)\n",
    "            for index in range(0, len(measure)):\n",
    "                if index < m or index + m + 1 > len(measure):\n",
    "                    continue   \n",
    "                sum1 = 0\n",
    "                for index_value in range(index - m, index + m + 1):\n",
    "                    sum1 = sum1 + measure[index_value]\n",
    "                result.append((1/((2*m)+1)) * sum1)\n",
    "        return result\n",
    "    \n",
    "    def save_PatternModel(self,file = ''):\n",
    "        #Save the target pattern to a json file\n",
    "        if file == '':\n",
    "            file = 'pattern'\n",
    "        with open(file + '.json', 'w') as filehandle:\n",
    "            json.dump(self.targetPattern, filehandle)\n",
    "\n",
    "    def load_PatternModel(self, file = ''):\n",
    "        #Load the target pattern from a json file\n",
    "        if file == '':\n",
    "            file = 'pattern'\n",
    "        with open(file + '.json') as json_file:\n",
    "            self.targetPattern = json.load(json_file)\n",
    "        return self.targetPattern\n",
    "            \n",
    "    def display_PatternModel(self):\n",
    "        #Generate the target pattern graph\n",
    "        f = plt.figure()\n",
    "        patternGraph = f.add_subplot(111)\n",
    "        patternGraph.plot(self.targetPattern)\n",
    "        plt.ylabel(\"Number of users\",fontsize=16)\n",
    "        plt.xlabel(\"Steps\",fontsize=16)\n",
    "        plt.title(\"Workload injection pattern\");\n",
    "        plt.grid();\n",
    "        plt.show()\n",
    "    \n",
    "    def generateRealProgressiveTargetPattern(self,nrounds,step,target_list):\n",
    "        #Generate the target pattern\n",
    "        self.targetPattern = []\n",
    "        patternChangeNumber = math.floor(nrounds/step)\n",
    "\n",
    "        target = target_list[0]\n",
    "        target_list_index = 0\n",
    "        mode = 1 #1 for increase, 0 for decrease\n",
    "        p_c = 1\n",
    "        for n in range(nrounds): \n",
    "                if n < (p_c * step):\n",
    "                    self.targetPattern.append(target)\n",
    "                elif p_c <= patternChangeNumber:\n",
    "                    p_c = p_c + 1\n",
    "                    if mode == 1:\n",
    "                        if target_list_index < (len(target_list) - 1):\n",
    "                            target_list_index += 1\n",
    "                        else:\n",
    "                            mode = 0\n",
    "                    else:\n",
    "                        if target_list_index > 0:\n",
    "                            target_list_index -= 1\n",
    "                        else:\n",
    "                            mode = 1\n",
    "                    target = target_list[target_list_index]\n",
    "                    self.targetPattern.append(target)\n",
    "                else:\n",
    "                    self.targetPattern.append(target)\n",
    "        return self.targetPattern\n",
    "        \n",
    "    def changeInjector(self):\n",
    "        user_level = self.targetPattern[self.rounds]\n",
    "        if self.debug:\n",
    "            print(\"injector level:\", user_level)\n",
    "        if self.replay == False:\n",
    "            status, message = environment_orchestrator.setLocustUser(user=int(user_level),spawn_rate=1)\n",
    "            print(\"message:\", message)\n",
    "                                                            \n",
    "    def getContext(self):\n",
    "        states = []\n",
    "        if len(self.previous_states) == 0:\n",
    "            state = environment_orchestrator.getAgregatedState(components=[{'prometheus': 'front-dynamic-component','zipkin': 'front-dynamic-component-service.default.svc.cluster.local:80/*'}],replay=self.replay, record=self.record,load=self.targetPattern[self.rounds], level=self.level,useMetricServer = True)\n",
    "            self.previous_states.append(state['lastcomponentNumber'].to_numpy().astype(float)[0])\n",
    "            self.previous_states.append(state['duration'].to_numpy().astype(float)[0])\n",
    "            self.previous_duration = state['duration'].to_numpy().astype(float)[0]\n",
    "            self.previous_states.append(state['req_perc_sec'].to_numpy().astype(float)[0])\n",
    "            self.previous_rq = state['req_perc_sec'].to_numpy().astype(float)[0]\n",
    "            self.previous_states.append(state['cpu_usage_mean'].to_numpy().astype(float)[0]) \n",
    "        elif len(self.previous_states) != 0 and len(self.current_states) != 0:\n",
    "            self.previous_states = self.current_states\n",
    "            self.previous_duration = self.current_duration\n",
    "            self.previous_rq = self.current_rq\n",
    "          \n",
    "        self.current_states = []\n",
    "        state = environment_orchestrator.getAgregatedState(components=[{'prometheus': 'front-dynamic-component','zipkin': 'front-dynamic-component-service.default.svc.cluster.local:80/*'}],replay=self.replay, record=self.record,load=self.targetPattern[self.rounds], level=self.level,useMetricServer = True)\n",
    "        response_times = state['response_times'][0] \n",
    "        num_reqs_perc_sec = state['num_reqs_per_sec'][0]\n",
    "        num_fail_per_sec = state['num_fail_per_sec'][0]\n",
    "        self.current_states.append(state['lastcomponentNumber'].to_numpy().astype(float)[0])  \n",
    "        self.current_duration = state['duration'].to_numpy().astype(float)[0]\n",
    "        self.current_rq = state['req_perc_sec'].to_numpy().astype(float)[0]\n",
    "        self.current_states.append(state['cpu_usage_mean'].to_numpy().astype(float)[0])\n",
    "        \n",
    "        states = self.current_states\n",
    "        states = np.asmatrix(states)\n",
    "        if self.replay == False:\n",
    "            self.level = int(self.current_states[0])\n",
    "        if self.debug:\n",
    "            print(\"state returned:\", states)\n",
    "        return states\n",
    "        \n",
    "    def armStay(self,context):\n",
    "        if self.debug:\n",
    "            print(\"In action stay function\")\n",
    "            print(\"level in armStay:\", self.level)\n",
    "        previous_context = context\n",
    "        reward = self.computeReward(previous_context=previous_context,context = context, action = \"stay\",actionStep = 0)\n",
    "        return reward, context\n",
    "\n",
    "            \n",
    "    def armUp(self,context,actionStep = 1):\n",
    "        previous_context = context\n",
    "        if self.debug:\n",
    "            print(\"In action up function\")\n",
    "            print(\"actionStep:\", actionStep)\n",
    "            print(\"level in armUp:\", self.level)\n",
    "        if self.level + actionStep > self.max_level:\n",
    "            if self.debug:\n",
    "                print(\"upper limit reached\")\n",
    "            reward = 0\n",
    "        else:\n",
    "            if self.replay:\n",
    "                self.level += actionStep\n",
    "            else:\n",
    "                status, message = environment_orchestrator.incrementalKubernetesDeploymentScale(deployment=\"front-dynamic-component\",step=actionStep,waitKubernetes=True,waitPrometheus=True,useMetricServer = False)\n",
    "                print(\"message:\", message)\n",
    "            context = self.getContext()\n",
    "            reward = self.computeReward(previous_context = previous_context,context = context, action = \"up\",actionStep = actionStep)\n",
    "        return reward,context\n",
    "            \n",
    "    def armDown(self,context, actionStep = 1):\n",
    "        previous_context = context\n",
    "        if self.debug:\n",
    "            print(\"In action down function\")\n",
    "            print(\"actionStep:\", actionStep)\n",
    "            print(\"level in armDown:\", self.level)\n",
    "        if self.level + actionStep < self.min_level:\n",
    "            if self.debug:\n",
    "                print(\"lower limit reached\")\n",
    "            reward = 0\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(\"lower limit not reached\")\n",
    "            if self.replay:\n",
    "                self.level += actionStep\n",
    "            else:\n",
    "                status, message = environment_orchestrator.incrementalKubernetesDeploymentScale(deployment=\"front-dynamic-component\",step=actionStep,waitKubernetes=True,waitPrometheus=True,useMetricServer = False)\n",
    "                print(\"message:\", message)\n",
    "            context = self.getContext()\n",
    "            reward = self.computeReward(previous_context = previous_context,context = context, action = \"down\",actionStep = actionStep)\n",
    "        return reward,context\n",
    "        \n",
    "    def computeReward(self,previous_context,context, action,actionStep = 1):\n",
    "        if self.debug:\n",
    "            print(\"in compute reward function\")\n",
    "        if action == \"up\":    \n",
    "            if self.debug:\n",
    "                print(\"compute reward for action up\")\n",
    "                print(\"previous latency for reward computation:\", self.previous_duration)\n",
    "                print(\"latency for reward computation:\", self.current_duration)\n",
    "            if self.previous_duration > self.latency_ref:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "\n",
    "        if action == \"down\":\n",
    "            if self.debug:\n",
    "                print(\"compute reward for action down\")\n",
    "                print(\"previous latency for reward computation:\", self.previous_duration)\n",
    "                print(\"latency for reward computation:\", self.current_duration)\n",
    "            if self.current_duration <= self.latency_ref:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "                    \n",
    "        if action == \"stay\":\n",
    "            if self.debug:\n",
    "                print(\"Compute reward for action stay\")\n",
    "                print(\"previous latency for reward computation:\", self.previous_duration)\n",
    "                print(\"latency for reward computation:\", self.current_duration)\n",
    "            if self.current_duration <= self.latency_ref:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "        if self.debug:\n",
    "            print(\"returned reward:\", reward)\n",
    "        return reward\n",
    "        \n",
    "    def computeOracle(self):\n",
    "        with h5py.File(self.sessionFile, \"r\") as f:\n",
    "            for load in self.loads:\n",
    "                bestset = False\n",
    "                for level in self.levels:\n",
    "                    load_grp = f.get(str(load))\n",
    "                    component_grp = load_grp.get('front-dynamic-component')\n",
    "                    level_grp = component_grp.get(str(level))\n",
    "                    d = level_grp.get('measure')\n",
    "                    data = np.asarray(d)\n",
    "                    duration = data[:,3].astype(float)\n",
    "                     \n",
    "                    if np.mean(duration) <= self.latency_ref and np.max(duration) <= self.latency_ref:\n",
    "                        if not bestset:\n",
    "                            self.oracle_cheat[load,level] = 1\n",
    "                            bestset = True\n",
    "                        else:\n",
    "                            self.oracle_cheat[load,level] = 0\n",
    "            if self.debug:\n",
    "                print(\"oracle cheat:\", self.oracle_cheat)\n",
    "                \n",
    "    def oracle(self):\n",
    "        #Return the Oracle best action\n",
    "        return self.oracle_cheat[int(self.targetPattern[self.rounds]),int(self.current_states[0])]\n",
    "    \n",
    "    def oracleOptimalLevel(self):\n",
    "        #Return the Oracle best action\n",
    "        return np.where(self.oracle_cheat[int(self.targetPattern[self.rounds])] == 1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Wikibench workload pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the environment\n",
    "Environment = EnvTest(narms=3,level=1,max_level = 4)\n",
    "#Load pattern from a json file(pattern.json). This method has to be called each time an environment needs to use the target pattern\n",
    "Environment.load_PatternModel()\n",
    "#Display graphically the target pattern model\n",
    "Environment.display_PatternModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(Environment, Agent, nrounds=None, tie_break_mode = \"random\",DisplayCumulativeRewardGraph = False, debug = False):\n",
    "    environment_level = []\n",
    "    latency_history = []\n",
    "    latency_ref_history = []\n",
    "    T = 0\n",
    "    latency_error = 0\n",
    "    injector_level = np.zeros(nrounds)\n",
    "    pattern = Environment.targetPattern[0:nrounds]\n",
    "    assert Agent._K%2 != 0, 'Arms number must be impair'\n",
    "    arm_action_map = np.zeros(Agent._K)\n",
    "    for i in range(int((Agent._K-1)/2)):\n",
    "        arm_action_map[i] = int((-(Agent._K-1)/2) + i)\n",
    "    for i in range(int((Agent._K-1)/2)):\n",
    "        arm_action_map[i + 1 + (int((Agent._K-1)/2))] = int(i +1)\n",
    "    if debug:\n",
    "        print(\"arm action map:\", arm_action_map)\n",
    "\n",
    "    for i in range(nrounds):\n",
    "        Environment.rounds = i\n",
    "        Environment.changeInjector()     \n",
    "        context = Environment.getContext()\n",
    "        action, desiredReplicas = Agent.select(context,tie_break_mode)\n",
    "        desiredActionStep = desiredReplicas - Environment.current_states[0]       \n",
    "        if action < int((Agent._K-1)/2) :\n",
    "            reward,next_context = Environment.armDown(context = context,actionStep = int(desiredActionStep))\n",
    "        if action == int((Agent._K-1)/2):     \n",
    "            reward,next_context = Environment.armStay(context = context)\n",
    "        if action > int((Agent._K-1)/2):\n",
    "            reward,next_context = Environment.armUp(context = context,actionStep = int(desiredActionStep))\n",
    "\n",
    "        latency_history.append(Environment.current_duration)\n",
    "        injector_level[i] = Environment.targetPattern[i]\n",
    "        latency_ref_history.append(Environment.latency_ref)\n",
    "        if Environment.current_duration > Environment.latency_ref:\n",
    "            latency_error += 1\n",
    "        print(\"latency error:\", latency_error)\n",
    "        environment_level.append(Environment.current_states[0])\n",
    "        T +=1\n",
    "        if (DisplayCumulativeRewardGraph and T %5 == 0):\n",
    "            %matplotlib inline\n",
    "            clear_output(True)\n",
    "            fig, ax = plt.subplots(figsize=(6, 4), nrows=1, ncols=1)\n",
    "            plt.xlabel('steps',fontsize=16)\n",
    "            plt.ylabel(\"Number of users\",fontsize=16)\n",
    "            plt.xticks(fontsize=13,fontweight='normal')\n",
    "            plt.yticks(fontsize=13,fontweight='normal')\n",
    "            ax.plot(pattern,label=\"pattern\")\n",
    "            ax.plot(injector_level,label='current')\n",
    "            ax.grid()\n",
    "            ax.set_title('Real injection pattern')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            fig, ax = plt.subplots(figsize=(6, 4), nrows=1, ncols=1)\n",
    "            plt.xlabel('steps',fontsize=16)\n",
    "            plt.ylabel(\"Number of containers\",fontsize=16)\n",
    "            plt.xticks(fontsize=13,fontweight='normal')\n",
    "            plt.yticks(fontsize=13,fontweight='normal')\n",
    "            ax.plot(environment_level,label='Threshold')\n",
    "            ax.grid()\n",
    "            ax.set_title('Real environment level')\n",
    "            plt.tight_layout()\n",
    "            plt.legend(loc = 'upper right',prop={'size':20})\n",
    "            plt.show()\n",
    "            fig, ax = plt.subplots(figsize=(6, 4), nrows=1, ncols=1)\n",
    "            plt.xlabel('steps',fontsize=16)\n",
    "            plt.ylabel(\"Latency(ms)\",fontsize=16)\n",
    "            plt.xticks(fontsize=13,fontweight='normal')\n",
    "            plt.yticks(fontsize=13,fontweight='normal')\n",
    "            ax.plot(latency_history,label='Threshold')\n",
    "            ax.plot(latency_ref_history,label=r'$l^{*}$')\n",
    "            ax.grid()\n",
    "            ax.set_title('Real latency')\n",
    "            plt.tight_layout()\n",
    "            plt.legend(loc = 'upper right',prop={'size':20})\n",
    "            plt.show()   \n",
    "\n",
    "    return injector_level,latency_ref_history,latency_history, environment_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hpa():\n",
    "    \n",
    "    def __init__(self,K, alpha = 1):\n",
    "        self._K = K\n",
    "        self._alpha = alpha\n",
    "\n",
    "    def select(self, context, tie_break_mode = \"random\"):\n",
    "\n",
    "        desiredReplicas = math.ceil(context[0,0] * ( (context[0,1]) / self._alpha ))\n",
    "        print(\"desired replica:\", desiredReplicas)\n",
    "        if desiredReplicas < context[0,0]:\n",
    "            print(\"choose down\")\n",
    "            return 0,desiredReplicas\n",
    "            \n",
    "        if desiredReplicas == context[0,0]:\n",
    "            print(\"choose stay\")\n",
    "            return 1,desiredReplicas\n",
    "            \n",
    "        if desiredReplicas > context[0,0]:\n",
    "            print(\"choose up\")\n",
    "            return 2,desiredReplicas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Hpa threshold on real environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "latency_ref = 600\n",
    "starting_level = 1 #The environement will start at this specified level\n",
    "max_level = 10 #10 #The number of levels that can be managed in the environment\n",
    "#Agent setup\n",
    "nrounds = 912\n",
    "Arms=3 #Number of actions (must be impair)\n",
    "exploration = 470  #Threshold level\n",
    "tie_break_mode = \"random\" #Action selection mode when tied. Possible value: \"random\", \"min\", \"max\"\n",
    "displayDynamicGraph = True #If True display regret and environment change dynamicaly. This dramatically increases the simulation time. Change this value require a full restart of the notebook as the graphic rendering engine change.\n",
    "ExperimentNumber = 10\n",
    "environment_level_exp = np.empty((ExperimentNumber, nrounds))\n",
    "latency_exp = np.empty((ExperimentNumber, nrounds))\n",
    "latency_reference_exp = np.empty((ExperimentNumber, nrounds))\n",
    "injector_level_exp = np.empty((ExperimentNumber, nrounds))\n",
    "for experiment in trange(ExperimentNumber):\n",
    "    #Create environment\n",
    "    Environment = EnvTest(Arms,level=starting_level,max_level = max_level,latency_ref = latency_ref, debug = debug)\n",
    "    Environment.load_PatternModel()\n",
    "    #Create Agent\n",
    "    Agent = Hpa(Arms, alpha = exploration)\n",
    "    #Start simulation\n",
    "    print(\"set current locust user to 45 (injection is started automatically if currently stopped)\")\n",
    "    status, message = environment_orchestrator.setLocustUser(user=45,spawn_rate=1)\n",
    "    print(\"message:\", message)\n",
    "    print(\"set current container number to 5\")\n",
    "    status, message = environment_orchestrator.setKubernetesDeploymentScale(deployment=\"front-dynamic-component\",number=5,waitKubernetes=True,waitPrometheus=True, useMetricServer = False)\n",
    "    print(\"message:\", message)\n",
    "    print(\"Wait 5 seconds for injector to send some requests..\")\n",
    "    time.sleep(5)\n",
    "    injector_level,latency_ref_history,latency, environment_level = Evaluate(Environment, Agent, nrounds=nrounds, tie_break_mode=tie_break_mode ,DisplayCumulativeRewardGraph = displayDynamicGraph, debug = debug)\n",
    "    injector_level_exp[experiment] = injector_level\n",
    "    latency_reference_exp[experiment] = latency_ref_history\n",
    "    latency_exp[experiment] = latency\n",
    "    environment_level_exp[experiment] = environment_level\n",
    "    \n",
    "with open(\"hpa_injector_level.bin\", 'wb') as f:\n",
    "    np.save(f , injector_level_exp)\n",
    "with open(\"hpa_latency_reference.bin\", 'wb') as f:\n",
    "    np.save(f , latency_reference_exp)\n",
    "with open(\"hpa_latency.bin\", 'wb') as f:\n",
    "    np.save(f , latency_exp)\n",
    "with open(\"hpa_environment_level.bin\", 'wb') as f:\n",
    "    np.save(f , environment_level_exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
